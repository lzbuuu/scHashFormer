# scHashFormer
The code of Fast and Scalable scRNA-seq Clustering via Local Attention.
In this paper, we present \textbf{scHashFormer}, which replaces all-pairs computation with \emph{learnable locality-sensitive hashing} to group transcriptionally similar cells into high-purity hash neighbourhoods in near-linear time. Within each neighbourhood, a lightweight Transformer performs message passing to learn structure-aware embeddings. Training is regularised by a zero-inflated negative binomial (ZINB) objective, removing the need for an explicit global graph. Across datasets spanning 1e4-1e6 cells, scHashFormer outperforms leading methods while reducing runtime and memory by up to an order of magnitude and avoiding out-of-memory failures. The resulting embeddings improve cell-type annotation, better separate rare and transitional populations, enable batch-robust integration without over-mixing, and preserve developmental trajectories consistent with lineage markers. Together, scHashFormer makes million-cell clustering and downstream single-cell analyses routine and reproducible at the atlas scale.
